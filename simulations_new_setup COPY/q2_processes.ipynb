{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 â€“ Which DGP Processes Are Best Captured by Each Model?\n",
    "\n",
    "This notebook investigates which data-generating processes (DGPs) are best approximated by each model's forecast distribution, using KL divergence as the evaluation metric.\n",
    "\n",
    "### Objective\n",
    "- Identify the DGPs that each model captures most accurately.\n",
    "- Compare model fit across processes and context lengths.\n",
    "\n",
    "### Key Outputs\n",
    "- ðŸ“„ Tables:\n",
    "  - KL divergence per DGP and day, sorted by model and average KL\n",
    "  - Separate tables for prices and returns\n",
    "\n",
    "- ðŸ“Š Plots:\n",
    "  - KL divergence across context lengths\n",
    "\n",
    "### Notes\n",
    "- Models listed in `selected_model_names` only\n",
    "- KL divergence is computed between model forecasts and ground-truth DGP samples\n",
    "- For prices, returns are first computed before evaluating KL\n",
    "- Forecast horizons: `Day 2`, `Day 12`, `Day 22`\n",
    "- Results are sorted within each model by average KL (per DGP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.evaluation import (\n",
    "    compute_kl_divergence,\n",
    "    format_pivot_table,\n",
    "    dataframe_to_latex\n",
    ")\n",
    "\n",
    "from utils.plotting import plot_kl_vs_context\n",
    "\n",
    "# Needed to avoid issues with numpy for TimesFM 2.5\n",
    "import sys, numpy.core.numeric as numeric\n",
    "sys.modules['numpy._core.numeric'] = numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models List\n",
    "\n",
    "Models can be added or removed from the followng list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected Models for Analysis\n",
    "selected_model_names = [\n",
    "    \"chronos_model_tiny\",\n",
    "    \"chronos_model_mini\",\n",
    "    \"chronos_model_base\",\n",
    "    \"lag_llama_model\",\n",
    "    \"moirai_model_small\",\n",
    "    \"moirai_model_base\",\n",
    "    \"moirai_model_small_2_0\",   # NEW\n",
    "    \"moirai_model_small_1_1\",   # NEW\n",
    "    \"moirai_model_base_1_1\",    # NEW\n",
    "    \"toto_model\",\n",
    "    \"tirex_model\",\n",
    "    \"timesfm_model_small\",\n",
    "    \"timesfm_model_large\",\n",
    "    \"timesfm_model_2_5\"        # NEW\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and Setup\n",
    "results_dir = Path(\"results_q2_processes\")\n",
    "tables_dir = results_dir / \"tables\"\n",
    "plots_dir = {\n",
    "    name: results_dir / name for name in [\"plots_context\"]\n",
    "}\n",
    "\n",
    "for folder in [tables_dir, *plots_dir.values()]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "forecast_dir = Path(\"forecasts\")\n",
    "run_dir = Path(\"runfiles\")\n",
    "datasets_dir = Path(\"datasets\")\n",
    "\n",
    "selected_days = [0, 10, 20]\n",
    "context_lengths = [22, 66, 252]\n",
    "\n",
    "dgp_types_kl = [\"gbm_low_vol\", \"gbm_high_vol\", \"garch\", \"t_garch\", \"mixture_normal\", \"seasonal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Forecasts\n",
    "\n",
    "We load the forecasts and retrieve the specifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Forecasts\n",
    "forecast_files = sorted(forecast_dir.glob(\"forecast_*.pkl\"))\n",
    "results = []\n",
    "\n",
    "for forecast_file in forecast_files:\n",
    "    run_name = forecast_file.stem\n",
    "    run_file = run_dir / f\"{run_name}.txt\"\n",
    "    if not run_file.exists():\n",
    "        continue\n",
    "\n",
    "    run_config = {}\n",
    "    with open(run_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"=\" in line:\n",
    "                key, value = [x.strip() for x in line.strip().split(\"=\", 1)]\n",
    "                try:\n",
    "                    run_config[key] = eval(value)\n",
    "                except:\n",
    "                    run_config[key] = value.strip(\"\\\"'\").strip(\"'\")\n",
    "\n",
    "    try:\n",
    "        with open(forecast_file, \"rb\") as f:\n",
    "            forecast_result = pickle.load(f)\n",
    "            low, median, high, samples, base_price = forecast_result\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    results.append({\n",
    "        \"run_name\": run_name,\n",
    "        \"model_name\": run_config[\"model_name\"],\n",
    "        \"dgp_type\": run_config[\"dataset_name\"],\n",
    "        \"target_type\": run_config[\"target_type\"],\n",
    "        \"context_length\": run_config[\"context_length\"],\n",
    "        \"samples\": samples,\n",
    "        \"low\": low,\n",
    "        \"median\": median,\n",
    "        \"high\": high,\n",
    "        \"base_price\": base_price\n",
    "    })\n",
    "\n",
    "# Filter Results by Selected Models\n",
    "results = [r for r in results if r[\"model_name\"] in selected_model_names]\n",
    "\n",
    "price_results = [r for r in results if r[\"target_type\"] == \"prices\"]\n",
    "return_results = [r for r in results if r[\"target_type\"] == \"returns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique model names found in runfiles:\n",
      "'chronos_model_base'\n",
      "'chronos_model_mini'\n",
      "'chronos_model_tiny'\n",
      "'lag_llama_model'\n",
      "'moirai_model_base'\n",
      "'moirai_model_base_1_1'\n",
      "'moirai_model_small'\n",
      "'moirai_model_small_1_1'\n",
      "'moirai_model_small_2_0'\n",
      "'timesfm_model_2_5'\n",
      "'timesfm_model_large'\n",
      "'timesfm_model_small'\n",
      "'tirex_model'\n",
      "'toto_model'\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique model names found in runfiles:\")\n",
    "for name in sorted(set(r[\"model_name\"] for r in results)):\n",
    "    print(f\"'{name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions\n",
    "\n",
    "We define 2 new special functions to save tables and compute the KL divergence compatible with this notebook setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute KL Divergence and Store for Sorting\n",
    "def compute_kl_with_average(results_subset):\n",
    "    df_rows = []\n",
    "\n",
    "    for item in results_subset:\n",
    "        if item[\"dgp_type\"] not in dgp_types_kl:\n",
    "            continue\n",
    "\n",
    "        is_price = item[\"target_type\"] == \"prices\"\n",
    "        model_returns = item[\"samples\"]\n",
    "        if is_price:\n",
    "            model_returns = model_returns[:, 1:] / model_returns[:, :-1] - 1\n",
    "\n",
    "        dgp_path = datasets_dir / f\"{item['dgp_type']}_returns_paths.npy\"\n",
    "        if not dgp_path.exists():\n",
    "            continue\n",
    "\n",
    "        dgp_returns = np.load(dgp_path)\n",
    "\n",
    "        kl_values = {}\n",
    "        for day_index in selected_days:\n",
    "            try:\n",
    "                p = dgp_returns[:, day_index]\n",
    "                q = model_returns[:, day_index]\n",
    "                kl = compute_kl_divergence(p, q)\n",
    "                df_rows.append({\n",
    "                    \"context_length\": item[\"context_length\"],\n",
    "                    \"dgp_type\": item[\"dgp_type\"],\n",
    "                    \"model_name\": item[\"model_name\"],\n",
    "                    \"day\": f\"Day {day_index + 2}\",\n",
    "                    \"kl_divergence\": kl\n",
    "                })\n",
    "                kl_values[day_index] = kl\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    df_kl = pd.DataFrame(df_rows).round(4)\n",
    "\n",
    "    # Compute average KL across selected days\n",
    "    df_avg = df_kl.groupby([\"context_length\", \"dgp_type\", \"model_name\"])[\"kl_divergence\"].mean().reset_index()\n",
    "    df_avg.rename(columns={\"kl_divergence\": \"avg_kl\"}, inplace=True)\n",
    "\n",
    "    return df_kl, df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Model-wise Sorted KL Tables\n",
    "def save_sorted_kl_tables_by_model(df_kl, df_avg_kl, label):\n",
    "    for context in context_lengths:\n",
    "        df_filtered = df_kl[df_kl[\"context_length\"] == context]\n",
    "        avg_filtered = df_avg_kl[df_avg_kl[\"context_length\"] == context]\n",
    "\n",
    "        # KL pivot table: (context, dgp, model) Ã— day\n",
    "        pivot = df_filtered.pivot_table(\n",
    "            index=[\"context_length\", \"dgp_type\", \"model_name\"],\n",
    "            columns=\"day\",\n",
    "            values=\"kl_divergence\"\n",
    "        )\n",
    "\n",
    "        # Build fully sorted index per model\n",
    "        sorted_blocks = []\n",
    "\n",
    "        for model_name in avg_filtered[\"model_name\"].unique():\n",
    "            df_model_avg = avg_filtered[avg_filtered[\"model_name\"] == model_name]\n",
    "            df_model_avg = df_model_avg.sort_values(\"avg_kl\")\n",
    "\n",
    "            sorted_index = [(context, row[\"dgp_type\"], model_name) for _, row in df_model_avg.iterrows()]\n",
    "            index_in_pivot = [idx for idx in sorted_index if idx in pivot.index]\n",
    "\n",
    "            if index_in_pivot:  # Only if there's data\n",
    "                group_sorted = pivot.loc[index_in_pivot]\n",
    "                sorted_blocks.append(group_sorted)\n",
    "\n",
    "        if not sorted_blocks:\n",
    "            print(f\"[SKIP] No data to save for context length {context} and label {label}\")\n",
    "            continue  # Skip this context safely\n",
    "\n",
    "        pivot_sorted = pd.concat(sorted_blocks)\n",
    "\n",
    "        # Format & Save\n",
    "        formatted = format_pivot_table(pivot_sorted, selected_days)\n",
    "        filename = f\"q2_kl_sorted_{label}_context{context}.tex\"\n",
    "        dataframe_to_latex(formatted, tables_dir / filename, preserve_index_order=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and Save KL Tables (by model, correctly sorted)\n",
    "df_kl_prices, df_avg_prices = compute_kl_with_average(price_results)\n",
    "df_kl_returns, df_avg_returns = compute_kl_with_average(return_results)\n",
    "\n",
    "save_sorted_kl_tables_by_model(df_kl_prices, df_avg_prices, \"prices\")\n",
    "save_sorted_kl_tables_by_model(df_kl_returns, df_avg_returns, \"returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Only the specific figure is here plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context & Bar Plots\n",
    "plot_kl_vs_context(df_kl_prices, plots_dir[\"plots_context\"], \"prices\")\n",
    "plot_kl_vs_context(df_kl_returns, plots_dir[\"plots_context\"], \"returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Which DGPs Are Best Captured by the Models?\n",
    "\n",
    "We analyze KL divergence at context length 22 to assess which data-generating processes (DGPs) are most effectively captured by the models. Lower KL indicates better alignment between forecasted and true distributions. The analysis includes both price and return forecasts across selected DGPs.\n",
    "\n",
    "**Price Forecasts**\n",
    "\n",
    "- gbm_high_vol is the most reliably captured process. Most models, including Chronos variants, Toto, Tirex, and Lag-Llama, achieve very low KL divergenceâ€”often below 0.1. This indicates that even relatively simple architectures can model this DGP well, even with short historical context.\n",
    "\n",
    "- seasonal and mixture_normal are captured with moderate success. Chronos models handle these processes reasonably well, while models like Moirai small show higher divergence, especially at intermediate horizons. Tirex and Toto offer strong and stable performance across all forecast days.\n",
    "\n",
    "- t_garch is the most difficult process for price-level modeling. KL values are consistently high, regardless of architecture. Chronos performs particularly poorly, while Toto and Tirex manage to reduce divergence slightly at shorter horizons, though no model excels on this DGP.\n",
    "\n",
    "- gbm_low_vol displays inconsistent results. Some models, such as Chronos mini and base, show sharp KL spikes at later forecast days, whereas others like Tirex and Toto remain more stable. This suggests that certain architectures may overfit or misrepresent low-volatility dynamics when predicting prices.\n",
    "\n",
    "**Return Forecasts**\n",
    "\n",
    "- Lag-Llama is the top performer. It achieves near-zero KL values across all DGPs except for a modest increase on t_garch. Its ability to capture both simple (gbm_low_vol, gbm_high_vol) and complex (mixture_normal, seasonal) return processes from short contexts is unmatched.\n",
    "\n",
    "- Toto performs strongly across the board. It handles mixture_normal, seasonal, and gbm_low_vol with KL values consistently below 0.1, showing excellent generalization even at short context length.\n",
    "\n",
    "- Tirex offers solid results across nearly all DGPs. While it struggles mildly with t_garch, it maintains low and stable KL divergence elsewhere, reflecting strong return modeling capabilities.\n",
    "\n",
    "- Moirai (base and small) achieves reasonable alignment on simpler DGPs like gbm_high_vol and seasonal. Although it does not reach the same performance level as Lag-Llama or Toto, it improves steadily across forecast days and maintains moderate KL values overall.\n",
    "\n",
    "- Chronos (base, mini, tiny) falls short in return forecasting. KL divergence is high across all DGPs, particularly for gbm_high_vol, mixture_normal, and t_garch. This suggests that the Chronos architecture may not effectively capture return dynamics with limited historical input.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "At context length 22, gbm_high_vol emerges as the most learnable DGP, showing low KL across nearly all models. In contrast, t_garch proves most challenging, especially for models like Chronos and Moirai. Lag-Llama, Toto, and Tirex stand out as robust performers, consistently delivering accurate forecasts across both simple and complex DGPs in the return and price spaces.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
