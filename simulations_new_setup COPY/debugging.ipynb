{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Loading Forecast → forecasts/forecast_001.pkl\n",
      "\n",
      "[Forecast Contents]\n",
      "  Low shape:     (22,)\n",
      "  Median shape:  (22,)\n",
      "  High shape:    (22,)\n",
      "  Samples shape: (1000, 22)\n",
      "  Base price:    108.7803232 (float64)\n",
      "\n",
      "[DGP Paths]\n",
      "  ✅ Price paths loaded:  gbm_low_vol_paths.npy → (1000, 22)\n",
      "  ✅ Return paths loaded: gbm_low_vol_returns_paths.npy → (1000, 22)\n"
     ]
    }
   ],
   "source": [
    "# Config: Forecast 001 (prices)\n",
    "forecast_file = Path(\"forecasts/forecast_001.pkl\")\n",
    "dgp_name = \"gbm_low_vol\"\n",
    "dgp_type = \"prices\"\n",
    "\n",
    "print(f\"\\n[1] Loading Forecast → {forecast_file}\")\n",
    "with open(forecast_file, \"rb\") as f:\n",
    "    forecast_result = pickle.load(f)\n",
    "\n",
    "print(\"\\n[Forecast Contents]\")\n",
    "if isinstance(forecast_result, (list, tuple)) and len(forecast_result) == 5:\n",
    "    low, median, high, samples, base_price = forecast_result\n",
    "    print(f\"  Low shape:     {low.shape}\")\n",
    "    print(f\"  Median shape:  {median.shape}\")\n",
    "    print(f\"  High shape:    {high.shape}\")\n",
    "    print(f\"  Samples shape: {samples.shape}\")\n",
    "    print(f\"  Base price:    {base_price} ({type(base_price).__name__})\")\n",
    "else:\n",
    "    print(\"❌ Unexpected forecast format:\")\n",
    "    print(forecast_result)\n",
    "\n",
    "# Load DGP paths\n",
    "price_path_file = Path(f\"datasets/{dgp_name}_paths.npy\")\n",
    "return_path_file = Path(f\"datasets/{dgp_name}_returns_paths.npy\")\n",
    "\n",
    "print(\"\\n[DGP Paths]\")\n",
    "if price_path_file.exists():\n",
    "    price_paths = np.load(price_path_file)\n",
    "    print(f\"  ✅ Price paths loaded:  {price_path_file.name} → {price_paths.shape}\")\n",
    "else:\n",
    "    print(f\"  ❌ Price paths not found: {price_path_file}\")\n",
    "\n",
    "if return_path_file.exists():\n",
    "    return_paths = np.load(return_path_file)\n",
    "    print(f\"  ✅ Return paths loaded: {return_path_file.name} → {return_paths.shape}\")\n",
    "else:\n",
    "    print(f\"  ❌ Return paths not found: {return_path_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Loading Forecast → forecasts/forecast_002.pkl\n",
      "\n",
      "[Forecast Contents]\n",
      "  Low shape:     (22,)\n",
      "  Median shape:  (22,)\n",
      "  High shape:    (22,)\n",
      "  Samples shape: (1000, 22)\n",
      "  Base value:    0.00285448 (ignored)\n",
      "\n",
      "[DGP Return Paths]\n",
      "  ✅ Loaded: gbm_low_vol_returns_paths.npy → (1000, 22)\n",
      "\n",
      "[Shape Check]\n",
      "  ✅ Forecast and DGP return shapes match!\n"
     ]
    }
   ],
   "source": [
    "# Config: Forecast 002 (returns)\n",
    "forecast_file = Path(\"forecasts/forecast_002.pkl\")\n",
    "dgp_type = \"returns\"\n",
    "\n",
    "print(f\"\\n[2] Loading Forecast → {forecast_file}\")\n",
    "with open(forecast_file, \"rb\") as f:\n",
    "    forecast_result = pickle.load(f)\n",
    "\n",
    "print(\"\\n[Forecast Contents]\")\n",
    "if isinstance(forecast_result, (list, tuple)) and len(forecast_result) == 5:\n",
    "    low, median, high, samples, base_value = forecast_result\n",
    "    print(f\"  Low shape:     {low.shape}\")\n",
    "    print(f\"  Median shape:  {median.shape}\")\n",
    "    print(f\"  High shape:    {high.shape}\")\n",
    "    print(f\"  Samples shape: {samples.shape}\")\n",
    "    print(f\"  Base value:    {base_value} (ignored)\")\n",
    "else:\n",
    "    print(\"❌ Unexpected forecast format:\")\n",
    "    print(forecast_result)\n",
    "\n",
    "# Load DGP returns\n",
    "return_path_file = Path(f\"datasets/{dgp_name}_returns_paths.npy\")\n",
    "print(\"\\n[DGP Return Paths]\")\n",
    "\n",
    "if return_path_file.exists():\n",
    "    return_paths = np.load(return_path_file)\n",
    "    print(f\"  ✅ Loaded: {return_path_file.name} → {return_paths.shape}\")\n",
    "    print(\"\\n[Shape Check]\")\n",
    "    if return_paths.shape == samples.shape:\n",
    "        print(\"  ✅ Forecast and DGP return shapes match!\")\n",
    "    else:\n",
    "        print(\"  ❌ Shape mismatch!\")\n",
    "        print(f\"     Forecast shape: {samples.shape}\")\n",
    "        print(f\"     DGP shape:      {return_paths.shape}\")\n",
    "else:\n",
    "    print(f\"  ❌ Return paths not found: {return_path_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] Price Path Diagnostic\n",
      "  Last historical price: 108.78032320\n",
      "  Simulated paths shape: (1000, 22)\n",
      "\n",
      "  ➤ First column equals last price? False\n",
      "  ⚠️ Unique start prices (first 5): [107.14900163 107.18790803 107.19726354 107.24064519 107.24310287]\n",
      "  ⚠️ Mean deviation from last price: 0.4418434255\n"
     ]
    }
   ],
   "source": [
    "# Price Start Diagnostic\n",
    "prices_csv_path = Path(f\"datasets/{dgp_name}_prices.csv\")\n",
    "paths_npy_path = Path(f\"datasets/{dgp_name}_paths.npy\")\n",
    "\n",
    "print(\"\\n[3] Price Path Diagnostic\")\n",
    "if not prices_csv_path.exists() or not paths_npy_path.exists():\n",
    "    print(\"❌ Required files not found.\")\n",
    "else:\n",
    "    historical_prices = pd.read_csv(prices_csv_path).squeeze()\n",
    "    last_price = historical_prices.iloc[-1]\n",
    "    simulated_paths = np.load(paths_npy_path)\n",
    "\n",
    "    print(f\"  Last historical price: {last_price:.8f}\")\n",
    "    print(f\"  Simulated paths shape: {simulated_paths.shape}\")\n",
    "\n",
    "    first_column = simulated_paths[:, 0]\n",
    "    match = np.allclose(first_column, last_price, rtol=0, atol=1e-8)\n",
    "\n",
    "    print(f\"\\n  ➤ First column equals last price? {match}\")\n",
    "    if not match:\n",
    "        unique_start_prices = np.unique(first_column)\n",
    "        mean_deviation = np.mean(np.abs(first_column - last_price))\n",
    "        print(f\"  ⚠️ Unique start prices (first 5): {unique_start_prices[:5]}\")\n",
    "        print(f\"  ⚠️ Mean deviation from last price: {mean_deviation:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] Return Path Diagnostic\n",
      "  Last historical return: 0.00285448\n",
      "  Simulated return paths shape: (1000, 22)\n",
      "\n",
      "  ➤ First column equals last return? False\n",
      "  ⚠️ Unique start returns (first 5): [-0.01511006 -0.01474702 -0.01465974 -0.01425514 -0.01423222]\n",
      "  ⚠️ Mean deviation from last return: 0.0047165397\n"
     ]
    }
   ],
   "source": [
    "# Return Start Diagnostic\n",
    "returns_csv_path = Path(f\"datasets/{dgp_name}_returns.csv\")\n",
    "returns_paths_npy = Path(f\"datasets/{dgp_name}_returns_paths.npy\")\n",
    "\n",
    "print(\"\\n[4] Return Path Diagnostic\")\n",
    "if not returns_csv_path.exists() or not returns_paths_npy.exists():\n",
    "    print(\"❌ Required files not found.\")\n",
    "else:\n",
    "    historical_returns = pd.read_csv(returns_csv_path).squeeze()\n",
    "    last_return = historical_returns.iloc[-1]\n",
    "    simulated_returns = np.load(returns_paths_npy)\n",
    "\n",
    "    print(f\"  Last historical return: {last_return:.8f}\")\n",
    "    print(f\"  Simulated return paths shape: {simulated_returns.shape}\")\n",
    "\n",
    "    first_column = simulated_returns[:, 0]\n",
    "    match = np.allclose(first_column, last_return, rtol=0, atol=1e-8)\n",
    "\n",
    "    print(f\"\\n  ➤ First column equals last return? {match}\")\n",
    "    if not match:\n",
    "        unique_start_returns = np.unique(first_column)\n",
    "        mean_deviation = np.mean(np.abs(first_column - last_return))\n",
    "        print(f\"  ⚠️ Unique start returns (first 5): {unique_start_returns[:5]}\")\n",
    "        print(f\"  ⚠️ Mean deviation from last return: {mean_deviation:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
