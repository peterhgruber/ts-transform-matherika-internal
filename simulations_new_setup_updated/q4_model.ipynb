{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 â€“ Model Ranking by Average KL Divergence\n",
    "\n",
    "This notebook summarizes model performance across multiple data-generating processes (DGPs) using **average KL divergence** as the primary evaluation metric. We rank models by their ability to align with true forecast distributions, across different forecast horizons and context lengths.\n",
    "\n",
    "### Objective\n",
    "- Rank models by average KL divergence over selected DGPs and forecast days.\n",
    "- Compare performance across both price and return forecasts.\n",
    "- Identify which architectures generalize best across heterogeneous settings.\n",
    "\n",
    "### Evaluation Setup\n",
    "- Models are evaluated on five representative DGPs: `gbm_low_vol`, `gbm_high_vol`, `t_garch`, `mixture_normal`, and `seasonal`.\n",
    "- KL divergence is computed at Days 2, 12, and 22.\n",
    "- Scores are averaged per model, DGP, and context length.\n",
    "\n",
    "### Key Outputs\n",
    "- ðŸ“„ Tables:\n",
    "  - Average KL per model Ã— DGP Ã— context length (sorted)\n",
    "- ðŸ“Š Plots:\n",
    "  - Bar charts showing average KL across models (separately for prices and returns)\n",
    "\n",
    "### Notes\n",
    "- Both price and return targets are analyzed.\n",
    "- Only models in `selected_model_names` are included.\n",
    "- KL is always computed on **returns**, even for price forecasts (returns are derived before evaluation).\n",
    "\n",
    "This analysis provides a clean, global view of model qualityâ€”highlighting which architectures offer consistently accurate forecasts across different temporal and statistical regimes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.evaluation import (\n",
    "    compute_kl_divergence,\n",
    "    dataframe_to_latex\n",
    ")\n",
    "\n",
    "from utils.plotting import (\n",
    "    plot_model_comparison_bar_avg\n",
    ")\n",
    "\n",
    "# Needed to avoid issues with numpy for TimesFM 2.5\n",
    "import sys, numpy.core.numeric as numeric\n",
    "sys.modules['numpy._core.numeric'] = numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models List\n",
    "\n",
    "Models can be added or removed from the followng list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected Models for Analysis\n",
    "selected_model_names = [\n",
    "    \"chronos_model_tiny\",\n",
    "    \"chronos_model_mini\",\n",
    "    \"chronos_model_base\",\n",
    "    \"lag_llama_model\",\n",
    "    \"moirai_model_small\",\n",
    "    \"moirai_model_base\",\n",
    "    \"moirai_model_small_2_0\",   # NEW\n",
    "    \"moirai_model_small_1_1\",   # NEW\n",
    "    \"moirai_model_base_1_1\",    # NEW\n",
    "    \"toto_model\",\n",
    "    \"tirex_model\",\n",
    "    \"timesfm_model_small\",\n",
    "    \"timesfm_model_large\",\n",
    "    \"timesfm_model_2_5\"        # NEW\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and Setup\n",
    "results_dir = Path(\"results_q4_model\")\n",
    "tables_dir = results_dir / \"tables\"\n",
    "plots_dir = results_dir / \"plots_model_comparison\"\n",
    "tables_dir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "forecast_dir = Path(\"forecasts\")\n",
    "run_dir = Path(\"runfiles\")\n",
    "datasets_dir = Path(\"datasets\")\n",
    "\n",
    "selected_days = [0, 10, 20]\n",
    "ordered_days = [f\"Day {d+2}\" for d in selected_days]\n",
    "context_lengths = [22, 66, 252]\n",
    "\n",
    "dgp_types_kl = [\"gbm_low_vol\", \"gbm_high_vol\", \"garch\", \"t_garch\", \"mixture_normal\", \"seasonal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Forecasts\n",
    "\n",
    "We load the forecasts and retrieve the specifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Forecasts\n",
    "forecast_files = sorted(forecast_dir.glob(\"forecast_*.pkl\"))\n",
    "results = []\n",
    "\n",
    "for forecast_file in forecast_files:\n",
    "    run_name = forecast_file.stem\n",
    "    run_file = run_dir / f\"{run_name}.txt\"\n",
    "    if not run_file.exists():\n",
    "        continue\n",
    "\n",
    "    # Skip temperature-tuning runs\n",
    "    with open(run_file, \"r\") as f:\n",
    "        run_text = f.read()\n",
    "    if \"temperature\" in run_text:\n",
    "        continue\n",
    "\n",
    "    run_config = {}\n",
    "    with open(run_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if \"=\" in line:\n",
    "                key, value = [x.strip() for x in line.strip().split(\"=\", 1)]\n",
    "                try:\n",
    "                    run_config[key] = eval(value)\n",
    "                except:\n",
    "                    run_config[key] = value.strip(\"\\\"'\").strip(\"'\")\n",
    "\n",
    "    try:\n",
    "        with open(forecast_file, \"rb\") as f:\n",
    "            forecast_result = pickle.load(f)\n",
    "            low, median, high, samples, base_price = forecast_result\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    results.append({\n",
    "        \"run_name\": run_name,\n",
    "        \"model_name\": run_config[\"model_name\"],\n",
    "        \"dgp_type\": run_config[\"dataset_name\"],\n",
    "        \"target_type\": run_config[\"target_type\"],\n",
    "        \"context_length\": run_config[\"context_length\"],\n",
    "        \"samples\": samples,\n",
    "        \"low\": low,\n",
    "        \"median\": median,\n",
    "        \"high\": high,\n",
    "        \"base_price\": base_price\n",
    "    })\n",
    "\n",
    "# Filter Results by Selected Models\n",
    "results = [r for r in results if r[\"model_name\"] in selected_model_names]\n",
    "\n",
    "price_results = [r for r in results if r[\"target_type\"] == \"prices\"]\n",
    "return_results = [r for r in results if r[\"target_type\"] == \"returns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique model names found in runfiles:\n",
      "'chronos_model_base'\n",
      "'chronos_model_mini'\n",
      "'chronos_model_tiny'\n",
      "'lag_llama_model'\n",
      "'moirai_model_base'\n",
      "'moirai_model_base_1_1'\n",
      "'moirai_model_small'\n",
      "'moirai_model_small_1_1'\n",
      "'moirai_model_small_2_0'\n",
      "'timesfm_model_2_5'\n",
      "'timesfm_model_large'\n",
      "'timesfm_model_small'\n",
      "'tirex_model'\n",
      "'toto_model'\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique model names found in runfiles:\")\n",
    "for name in sorted(set(r[\"model_name\"] for r in results)):\n",
    "    print(f\"'{name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions\n",
    "\n",
    "We define 2 new special functions to save tables and compute the KL divergence compatible with this notebook setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute KL Divergence\n",
    "def compute_kl_dataframe(results_subset):\n",
    "    kl_rows = []\n",
    "\n",
    "    for item in results_subset:\n",
    "        if item[\"dgp_type\"] not in dgp_types_kl:\n",
    "            continue\n",
    "\n",
    "        is_price = item[\"target_type\"] == \"prices\"\n",
    "        model_returns = item[\"samples\"]\n",
    "        if is_price:\n",
    "            model_returns = model_returns[:, 1:] / model_returns[:, :-1] - 1\n",
    "\n",
    "        dgp_path = datasets_dir / f\"{item['dgp_type']}_returns_paths.npy\"\n",
    "        if not dgp_path.exists():\n",
    "            continue\n",
    "\n",
    "        dgp_returns = np.load(dgp_path)\n",
    "\n",
    "        for day_index in selected_days:\n",
    "            try:\n",
    "                p = dgp_returns[:, day_index]\n",
    "                q = model_returns[:, day_index]\n",
    "                kl = compute_kl_divergence(p, q)\n",
    "\n",
    "                kl_rows.append({\n",
    "                    \"context_length\": item[\"context_length\"],\n",
    "                    \"dgp_type\": item[\"dgp_type\"],\n",
    "                    \"model_name\": item[\"model_name\"],\n",
    "                    \"day\": f\"Day {day_index + 2}\",\n",
    "                    \"kl_divergence\": kl\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return pd.DataFrame(kl_rows).round(4)\n",
    "\n",
    "df_kl_prices = compute_kl_dataframe(price_results)\n",
    "df_kl_returns = compute_kl_dataframe(return_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Average KL Table\n",
    "def save_avg_kl_table(df_kl, label):\n",
    "    df_avg = (\n",
    "        df_kl[df_kl[\"day\"].isin([f\"Day {i + 2}\" for i in selected_days])]\n",
    "        .groupby([\"context_length\", \"dgp_type\", \"model_name\"])[\"kl_divergence\"]\n",
    "        .mean()\n",
    "        .reset_index(name=\"avg_kl\")\n",
    "    )\n",
    "\n",
    "    for context in context_lengths:\n",
    "        df_context = df_avg[df_avg[\"context_length\"] == context].copy()\n",
    "\n",
    "        # Keep context in final pivot for clarity\n",
    "        df_context[\"context_length\"] = context  # redundant but clear\n",
    "        df_context = df_context[[\"context_length\", \"dgp_type\", \"model_name\", \"avg_kl\"]]\n",
    "\n",
    "        # Pivot with multi-index for latex formatting\n",
    "        pivot = df_context.set_index([\"context_length\", \"dgp_type\", \"model_name\"]).sort_values(\"avg_kl\")\n",
    "\n",
    "        filename = f\"q4_avg_kl_{label}_context{context}.tex\"\n",
    "        dataframe_to_latex(pivot, tables_dir / filename, preserve_index_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Tables\n",
    "save_avg_kl_table(df_kl_prices, \"prices\")\n",
    "save_avg_kl_table(df_kl_returns, \"returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Only the specific figure is here plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Plots (Bar by Avg KL)\n",
    "plot_model_comparison_bar_avg(df_kl_prices, plots_dir, \"prices\", selected_days)\n",
    "plot_model_comparison_bar_avg(df_kl_returns, plots_dir, \"returns\", selected_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Model Ranking by Average KL at Context Length 22\n",
    "\n",
    "We rank models by their average KL divergence across five DGPs. Lower values indicate better alignment between model forecasts and true future distributions. Rankings are reported separately for price and return targets.\n",
    "\n",
    "**Price Forecasts**\n",
    "\n",
    "- The best-performing models are the three Chronos variants. Chronos tiny (0.04), base (0.05), and mini (0.08) top the ranking, driven by excellent performance on gbm_high_vol and seasonal DGPs.\n",
    "\n",
    "- Lag-Llama performs competitively, especially on high- and moderate-volatility DGPs (avg KL 0.11â€“0.35). Toto and Moirai base are also strong contenders on t_garch and mixture_normal.\n",
    "\n",
    "- Mid-tier models include Tirex, Toto, and Moirai base. They maintain KL values around 0.4â€“0.8 depending on DGP. TimesFM large performs similarly.\n",
    "\n",
    "- Lower-tier models show rising KL divergence across DGPs. TimesFM small and Moirai small often exceed 1.5, indicating unstable forecasts under short contexts.\n",
    "\n",
    "- The worst scores come from Chronos mini and base on gbm_low_vol (KL ~4.9), and Moirai small on seasonal (KL ~5.1), revealing sharp degradation in specific low-volatility or structured regimes.\n",
    "\n",
    "**Return Forecasts**\n",
    "\n",
    "- Lag-Llama dominates return forecasting. It ranks first across all DGPs with near-zero KL (0.01â€“0.04), showing unmatched consistency and precision.\n",
    "\n",
    "- Toto is also a top performer, particularly strong on gbm_low_vol and mixture_normal (KL ~0.04â€“0.06), though it struggles on t_garch (KL 4.62).\n",
    "\n",
    "- Moirai small and base rank next, achieving KL < 0.2 on simpler DGPs like seasonal and gbm_high_vol, but degrade significantly on t_garch and mixture_normal.\n",
    "\n",
    "- Tirex and TimesFM large maintain moderate performance, generally in the 0.2â€“0.5 KL range, but spike sharply on t_garch.\n",
    "\n",
    "- TimesFM small is consistently worse than its large counterpart, particularly on gbm_low_vol and mixture_normal.\n",
    "\n",
    "- Chronos performs worst by far. All three versions exceed KL 9.0 on most DGPs, with peaks above 15 on gbm_low_vol and mixture_normal. Chronos struggles across all return scenarios.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- For price forecasting, Chronos leads the ranking, especially on high-volatility processes.\n",
    "\n",
    "- For return forecasting, Lag-Llama is by far the best, with Toto close behind on simpler DGPs.\n",
    "\n",
    "- Chronos fails completely on return forecasts at short context.\n",
    "\n",
    "- Moirai, Tirex, and TimesFM perform moderately, but are sensitive to both model scale and DGP volatility.\n",
    "\n",
    "- t_garch remains the hardest DGP overall, exposing the weaknesses of nearly all models except Lag-Llama.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
